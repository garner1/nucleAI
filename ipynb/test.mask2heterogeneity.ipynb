{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../py')\n",
    "from graviti import *\n",
    "\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import sys\n",
    "import glob\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import *\n",
    "import plotly.express as px\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "import umap\n",
    "import networkx as nx\n",
    "from scipy import sparse, linalg\n",
    "import pickle\n",
    "from sklearn.preprocessing import normalize, scale\n",
    "from scipy.sparse import find\n",
    "from numpy.linalg import norm\n",
    "import timeit\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100000 # number of nuclei, use 0 value for full set\n",
    "nn = 10 # set the number of nearest neighbor in the umap-graph. Will be used in CovD as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = glob.glob('/media/garner1/hdd2/TCGA_polygons/luad/*.gz')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numb of cores\n",
    "num_cores = multiprocessing.cpu_count() # numb of cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGA-44-7659-01Z-00-DX1\n",
      "Loading the data\n",
      "With 434262 nuclei\n",
      "Downsampling 100000 nuclei\n",
      "Creating the UMAP graph\n",
      "Finding the neighborhood of the sampled nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the descriptor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:08<00:00, 12333.39it/s]\n",
      "  0%|          | 240/100000 [00:00<00:42, 2361.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the diversity index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:08<00:00, 11164.33it/s]\n",
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the edge diversity index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:39<00:00, 1004.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for dirpath in samples[:1]:\n",
    "    sample = os.path.basename(dirpath).split(sep='.')[0]; print(sample)\n",
    "\n",
    "    print('Loading the data')\n",
    "    df = pd.DataFrame()\n",
    "    fovs = glob.glob(dirpath+'/*/*.svs/*.pkl')\n",
    "    for fov in fovs:\n",
    "        data = pd.read_pickle(fov)\n",
    "        df = df.append(data, ignore_index = True)\n",
    "    df['area'] = df['area'].astype(float)\n",
    "    \n",
    "    print('With '+str(df.shape[0])+' nuclei')\n",
    "    \n",
    "    features = df.columns[2:];# print(features)\n",
    "    centroids = df.columns[:2];# print(centroids)\n",
    "\n",
    "    print('Downsampling '+str(size)+' nuclei')\n",
    "    if size == 0:\n",
    "        fdf = df \n",
    "    else:\n",
    "        fdf = df.sample(n=size) \n",
    "    pos = fdf[centroids].to_numpy() # Get the positions of centroids \n",
    "    fdf = fdf.rename(columns={\"Centroid X µm\": \"cx\", \"Centroid Y µm\": \"cy\"})\n",
    "    \n",
    "    print('Creating the UMAP graph')\n",
    "    A = space2graph(pos,nn)\n",
    "    \n",
    "    print('Finding the neighborhood of the sampled nodes')\n",
    "    X = df[centroids].to_numpy() # the full array of position\n",
    "    n_neighbors = df.shape[0]//size + 10\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='kd_tree',n_jobs=-1).fit(X) \n",
    "    distances, indices = nbrs.kneighbors(X) \n",
    "\n",
    "    data = scale(df[features].to_numpy(), with_mean=False) #get the morphological data and rescale the data by std \n",
    "    \n",
    "    # Parallel generation of the local covd\n",
    "    print('Generating the descriptor')\n",
    "    processed_list = Parallel(n_jobs=num_cores)(\n",
    "        delayed(covd_parallel_sparse)(node,data,indices) for node in tqdm(list(fdf.index))\n",
    "                                                   )    \n",
    "    # Construct the descriptor array\n",
    "    descriptor = np.zeros((len(processed_list),processed_list[0][1].shape[0]))\n",
    "    for r in range(len(processed_list)):\n",
    "        descriptor[r,:] = processed_list[r][1] # covd descriptors of the connected nodes\n",
    "        \n",
    "    # Get info about the graph\n",
    "    row_idx, col_idx, values = find(A) #A.nonzero() # nonzero entries\n",
    "    print('Generating the diversity index')\n",
    "    node_nn_diversity = Parallel(n_jobs=num_cores)(\n",
    "        delayed(covd_gradient_parallel)(node,descriptor,row_idx,col_idx,values) for node in tqdm(range(descriptor.shape[0]))\n",
    "    )\n",
    "    fdf['diversity'] = [sum(node_nn_diversity[node][2]) for node in range(descriptor.shape[0])]\n",
    "\n",
    "    filename = './'+str(sample)+'.size'+str(size)+'.graphNN'+str(nn)+'.covdNN'+str(n_neighbors)+'.nodeHI.pkl'\n",
    "    fdf.to_pickle(filename)\n",
    "\n",
    "    print('Generating the edge diversity index')\n",
    "    edges_list = Parallel(n_jobs=num_cores)(\n",
    "        delayed(edge_diversity_parallel)(node,neightbors,diversity,fdf) \n",
    "                               for (node, neightbors, diversity) in tqdm(node_nn_diversity)\n",
    "    )\n",
    "    edge_list = [item for sublist in edges_list for item in sublist]\n",
    "    edge_df = pd.DataFrame(edge_list, columns=[\"centroid_x\", \"centroid_y\",\"diversity\"]) \n",
    "    filename = './'+str(sample)+'.size'+str(size)+'.graphNN'+str(nn)+'.covdNN'+str(n_neighbors)+'.edgeHI.pkl'\n",
    "    edge_df.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show contour plot\n",
    "N = 100\n",
    "filename = 'test'\n",
    "contourPlot(fdf,N,np.mean,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show contour plot\n",
    "N = 20\n",
    "filename = 'test'\n",
    "contourPlot(edge_df[edge_df['diversity']<10],N,np.sum,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape\n",
      "(23, 11)\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "fdf['x_bin'] = pd.cut(fdf['centroid_x'], 2*N, labels=False) # define the x bin label\n",
    "fdf['y_bin'] = pd.cut(fdf['centroid_y'], N, labels=False) # define the y bin label\n",
    "\n",
    "table = pd.pivot_table(fdf,\n",
    "                       values='diversity',\n",
    "                       index=['x_bin'],\n",
    "                       columns=['y_bin'],\n",
    "                       aggfunc=np.sum, # take the mean of the entries in the bin\n",
    "                       fill_value=None\n",
    "                      )\n",
    "import numpy as np\n",
    "from skimage.io import imsave, imread\n",
    "\n",
    "image = np.array(np.nan_to_num(table.to_numpy()), dtype=np.uint8)\n",
    "\n",
    "imsave(\"test.png\", image)\n",
    "print(\"image shape\")\n",
    "print(image.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
