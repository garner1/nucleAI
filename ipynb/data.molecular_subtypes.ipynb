{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import sys  \n",
    "\n",
    "sys.path.insert(0, '../py')\n",
    "from graviti import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from  matplotlib import pyplot\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "sns.set(style='white')\n",
    "import umap\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function showing a feature distribution on the umap projection\n",
    "def show_umap_proj(feature,df):\n",
    "    dff = df[['x','y',feature]]\n",
    "    #print(dff[feature].value_counts())\n",
    "    fg = seaborn.FacetGrid(data=dff, \n",
    "                           hue=feature,\n",
    "                           height=10, aspect=1\n",
    "                          )\n",
    "    fg.map(pyplot.scatter, 'x', 'y',s=50,alpha=0.5).add_legend()\n",
    "    plt.text(-8.0, -3.0, str(dff[feature].value_counts()), \n",
    "            horizontalalignment='left', size='medium', color='black')#, weight='semibold')\n",
    "\n",
    "    filename = 'umap_'+str(feature)\n",
    "    plt.savefig(filename+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the distance structure of the individual clusters considering the neighborhood of each sample\n",
    "\n",
    "def show_pmi(df_merged,feature):\n",
    "    #feature = 'BRCA_Subtype_PAM50'\n",
    "\n",
    "    dff = df_merged[['x','y',feature]]\n",
    "    X = dff[['x','y']].to_numpy()\n",
    "    nbrs = NearestNeighbors(n_neighbors=10, algorithm='ball_tree').fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "    # Create a dataframe with inter-subtypes proximity countings\n",
    "\n",
    "    inter_types_df = pd.DataFrame()\n",
    "    for idx in range(indices.shape[0]):\n",
    "        list_of_types = [ dff[feature].to_list()[i] for i in list(indices[idx]) ]\n",
    "        source = list_of_types[0]\n",
    "        c = Counter(list_of_types)\n",
    "        df = pd.DataFrame.from_dict(c, orient='index').reset_index()\n",
    "        df = df.rename(columns={'index':'target', 0:'count'}) \n",
    "        df['source'] = df.shape[0]*[source] # add the source tissue column\n",
    "        inter_types_df = inter_types_df.append(df)\n",
    "\n",
    "    pv_data = pd.pivot_table(inter_types_df, index=[\"source\"], columns=[\"target\"], values=[\"count\"], aggfunc=np.sum)\n",
    "\n",
    "    c = Counter(dff[feature].to_list())\n",
    "    df_pmi = pd.DataFrame()\n",
    "    set1 = {s for s in set(inter_types_df.source) if s==s}\n",
    "    set2 = {t for t in set(inter_types_df.target) if t==t}\n",
    "    for s in set1:\n",
    "        for t in set2:\n",
    "            num = pv_data.loc[s,('count', t)]\n",
    "            den = c[s]*c[t]\n",
    "            pmi = np.log(dff.shape[0]*num/den) # the cooccurrence is evaluated using an analogue of the pointwise mutual information\n",
    "            df0 = pd.DataFrame([[s,t,num,c[s],c[t],pmi]], \n",
    "                           columns=['source','target','cooccurence','source_count','target_count','pmi'])\n",
    "            df_pmi = df_pmi.append( df0 )\n",
    "\n",
    "\n",
    "    # Plot the point-wise mutual information of the clusters\n",
    "    filename = 'PMI_'+str(feature)+'.10nn'\n",
    "\n",
    "    pv_pmi = df_pmi.pivot(index='source',columns='target',values='pmi')\n",
    "    plt.figure(figsize=(10,10))\n",
    "    ax = sns.heatmap(pv_pmi,annot=True, fmt=\".3\", cmap=\"Blues\")\n",
    "    ax.set_ylim([0,len(set1)])\n",
    "    ax.set_title(filename)\n",
    "    plt.savefig(filename+'.png')\n",
    "    #df_pmi.to_csv(filename+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2d umap projection for BRCA \n",
    "umap_proj_filename = '../data/descriptor_withI.umap.csv' \n",
    "umap_xy = pd.read_csv(umap_proj_filename)\n",
    "# Pase the sample id in order to compare with the subtype table\n",
    "umap_xy['Sample.ID'] = umap_xy['sample'].str.rsplit('-',n=3,expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the molecular subtype table from literature\n",
    "subtypes_filename = '../data/subtypes.csv'\n",
    "subtypes = pd.read_csv(subtypes_filename,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x', 'y', 'sample', 'Sample.ID', 'Tumor.Type',\n",
       "       'Included_in_previous_marker_papers', 'vital_status', 'days_to_birth',\n",
       "       'days_to_death', 'days_to_last_followup',\n",
       "       'age_at_initial_pathologic_diagnosis', 'pathologic_stage',\n",
       "       'Tumor_Grade', 'BRCA_Pathology', 'BRCA_Subtype_PAM50', 'CESC_Pathology',\n",
       "       'OV_Subtype', 'UCS_Histology', 'UCEC_Histology', 'MSI_status',\n",
       "       'HPV_Status', 'tobacco_smoking_history', 'CNV Clusters',\n",
       "       'Mutation Clusters', 'DNA.Methylation Clusters', 'mRNA Clusters',\n",
       "       'miRNA Clusters', 'lncRNA Clusters', 'Protein Clusters',\n",
       "       'PARADIGM Clusters', 'Pan-Gyn Clusters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two tables on the Sample.ID\n",
    "df_merged = pd.merge(umap_xy, subtypes, on=\"Sample.ID\").copy()\n",
    "df_merged.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature set\n",
    "feature_set = ['pathologic_stage','BRCA_Pathology', 'BRCA_Subtype_PAM50','CNV Clusters',\n",
    "               'Mutation Clusters', 'DNA.Methylation Clusters', 'mRNA Clusters','miRNA Clusters',\n",
    "               'lncRNA Clusters', 'Protein Clusters','PARADIGM Clusters', 'Pan-Gyn Clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature in feature_set:\n",
    "    show_umap_proj(feature,df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature in feature_set:\n",
    "    show_pmi(df_merged,feature) \n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised learning of molecular features\n",
    "We use the 2d UMAP projection to infer the annotated molecular subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.33 (+/- 0.01)\n",
      "Accuracy: 0.27 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "feature_set = ['pathologic_stage','BRCA_Pathology', 'BRCA_Subtype_PAM50','CNV Clusters',\n",
    "               'Mutation Clusters', 'DNA.Methylation Clusters', 'mRNA Clusters','miRNA Clusters',\n",
    "               'lncRNA Clusters', 'Protein Clusters','PARADIGM Clusters', 'Pan-Gyn Clusters']\n",
    "feature = 'Pan-Gyn Clusters'\n",
    "X_full = df_merged[['x','y',feature]].copy()\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=[feature], inplace=True)\n",
    "y = le.fit_transform(X_full[feature]) # label encode the target\n",
    "X_full.drop([feature], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    #X_train_full[cname].nunique() < 10 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=0, max_depth=3)\n",
    "probs = cross_val_predict(clf, X_full, y, cv=3,method='predict_proba')\n",
    "scores = cross_val_score(clf, X_full, y, cv=3)\n",
    "#print(probs)\n",
    "#print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "probs = cross_val_predict(clf, X_full, y, cv=3,method='predict_proba')\n",
    "scores = cross_val_score(clf, X_full, y, cv=3)\n",
    "#print(probs)\n",
    "#print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(random_state=0, max_depth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[138  35]\n",
      "  [ 35   7]]\n",
      "\n",
      " [[183  16]\n",
      "  [ 14   2]]\n",
      "\n",
      " [[ 55  58]\n",
      "  [ 45  57]]\n",
      "\n",
      " [[140  26]\n",
      "  [ 40   9]]\n",
      "\n",
      " [[204   5]\n",
      "  [  6   0]]]\n",
      "[[ 7  4 21  9  1]\n",
      " [ 5  2  6  3  0]\n",
      " [21  7 57 14  3]\n",
      " [ 7  4 28  9  1]\n",
      " [ 2  1  3  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "\n",
    "print(multilabel_confusion_matrix(y_valid, preds))\n",
    "print(confusion_matrix(y_valid, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
